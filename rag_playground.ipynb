{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import CSVLoader\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_community.llms.huggingface_pipeline import HuggingFacePipeline\n",
    "from langchain.chains.summarize import load_summarize_chain\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "from chromadb.config import Settings\n",
    "\n",
    "import time\n",
    "import os\n",
    "import statistics\n",
    "import re\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"5\" \n",
    "os.environ[\"WORLD_SIZE\"] = \"1\"\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = CSVLoader(\"./8_entry_demo_ready.csv\")\n",
    "documents = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# set cuda visible devices\n",
    "#os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"5\"\n",
    "embedding_function = HuggingFaceEmbeddings(\n",
    "    model_name='all-MiniLM-L6-v2',\n",
    "    model_kwargs={\"device\": device},\n",
    "    cache_folder='/local/work/baheryilmaz/.cache'\n",
    ")\n",
    "\n",
    "PERSIST_DIRECTORY=\"./chroma\"\n",
    "query = \"speeding with road bikes\"\n",
    "db = Chroma.from_documents(documents, embedding_function, persist_directory = PERSIST_DIRECTORY)\n",
    "docs_vanilla = db.similarity_search(query)\n",
    "print(docs_vanilla[0].page_content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_name = \"mistralai/Mistral-7B-Instruct-v0.2\"\n",
    "\n",
    "llm = HuggingFacePipeline.from_model_id(\n",
    "                model_id=llm_name,\n",
    "                task=\"text-generation\",\n",
    "                model_kwargs={\"temperature\": 0, \"max_length\": 1024, \"trust_remote_code\": True, \"cache_dir\": \"/local/work/baheryilmaz/.cache\"},\n",
    "                device=0\n",
    "            )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CHROMA_SETTINGS = Settings(\n",
    "        chroma_db_impl='duckdb+parquet',\n",
    "        persist_directory=PERSIST_DIRECTORY,\n",
    "        anonymized_telemetry=False\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interactive questions and answers\n",
    "while True:\n",
    "    query = input(\"\\nEnter a query: \")\n",
    "    if query == \"exit\":\n",
    "        break\n",
    "    if query.strip() == \"\":\n",
    "        continue\n",
    "    # Get the answer from the chain\n",
    "    start = time.time()\n",
    "    #docs = retriever.get_relevant_documents(query)\n",
    "    pattern = r\"(id)(\\W)*([0-9]+)\"\n",
    "    filter = {}\n",
    "    for match in re.finditer(pattern, query):\n",
    "        patient_id = match[3]\n",
    "        filter = {'source': f'source_documents/patient_{patient_id}.txt'}\n",
    "    docs_with_score = db.similarity_search_with_score(query, k = 2, filter=filter)\n",
    "    #docs_with_score = docs_vanilla\n",
    "    mean = statistics.mean([doc[1] for doc in docs_with_score])\n",
    "    docs = [doc for doc in docs_with_score if doc[1]<=mean]\n",
    "    doc_page_contens = [doc[0] for doc in docs_with_score if doc[1] <= mean]\n",
    "    #memory = ConversationBufferMemory(memory_key=\"text\")\n",
    "\n",
    "    prompt_template = \"\"\"Write a concise and short summary of the following text at the end. Keep it short and simple:\n",
    "    \n",
    "    {text}\n",
    "    \n",
    "    CONCISE SUMMARY:\"\"\"\n",
    "    PROMPT = PromptTemplate(template=prompt_template, input_variables=[\"text\"])\n",
    "    chain = load_summarize_chain(llm, chain_type=\"stuff\")\n",
    "    #answer = chain({\"input_documents\": doc_page_contens, \"human_input\": query}, return_only_outputs=True)\n",
    "    #answer = chain.run({\"input_documents\": doc_page_contens, \"human_input\": query})\n",
    "    answer = chain.run(doc_page_contens)\n",
    "    #res = qa(query)\n",
    "    #answer, docs = res['result'], [] if args.hide_source else res['source_documents']\n",
    "    end = time.time()\n",
    "\n",
    "    # Print the result\n",
    "    print(\"\\n\\n> Question:\")\n",
    "    print(query)\n",
    "    print(f\"\\n> Answer (took {round(end - start, 2)} s.):\")\n",
    "    print(answer)\n",
    "\n",
    "    # Print the relevant sources used for the answer\n",
    "    for document in docs:\n",
    "        print(\"\\n> \" + document[0].metadata[\"source\"] + \":\")\n",
    "        print(document[0].page_content)\n",
    "        print(\"\\n> Score: \" + str(document[1]))\n",
    "    #print(chain.memory.buffer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
